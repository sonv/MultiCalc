[["index.html", "MATH 104: Multivariable Calculus (brief notes) Spring 2025", " MATH 104: Multivariable Calculus (brief notes) Truong-Son Van Spring 2025 "],["disclaimer.html", "Disclaimer", " Disclaimer This is class notes for Multivariable Calculus at Fublbright University Vietnam. I claim no originality in this work as it is mostly taken from the reference books. However, all errors and typos are solely mine. "],["syllabus.html", "Syllabus Key dates Materials and references Homework Assessment Core content Time expectations Learning Support Wellbeing Tentative Course Schedule", " Syllabus Key information Instructor: Truong-Son Van Email: son.van+104@fulbright.edu.vn Class time: Mon &amp; Wed 3:00 pm - 4:30 pm Class Location: Classroom 1 Office hours: Mon &amp; Wed 9:00 am - 10:00 am or by email appointment Prerequisites: Calculus (MATH 101) Midterm: Wednesday, March 12, 2025 Final: Wednesday, May 14, 2025 Key dates Add/Drop end: Jan 17 Tet: Jan 23 - Feb 7 Pass/No pass: Feb 14 Withdrawal: Mar 14 Midterm break: Mar 17 - 21 Hung King: Apr 7 Independence &amp; Labor Days: Apr 30 - May 1 Spring Term end: May 16 Materials and references Textbook: Calculus Early Transcendental by Stewart. \\(8^{th}\\) edition. I have some brief notes online on this page for you to review some key points. However, reading the book is the best preparation. Additional References The following books are highly recommended. If you find the style of the videos doesn’t fit you and would love to have something concrete to read, they are your friends. Active Calculus: Multivariable by Schlicker et al. 2018 edition. (https://activecalculus.org/multi/preface-2.html) Thomas’ Calculus: Early Transcendentals by Hass, Heil, et al. \\(14^{th}\\) edition. Anything you can find on Google would work. Calculus is a subject that people have written about so much. So, there’s no excuse for not having access to the knowledge. 3-D grapher: https://www.math3d.org/ Very good graphers: https://www.desmos.com/, https://www.geogebra.org/ Course description How do we describe the trajectory of a space shuttle? How is the human body affected by scuba diving to different depths for different lengths of time? The mathematics required to describe most real life systems involves functions of more than one variable. The concepts of the derivative and integral from a first course in calculus must therefore be extended to higher dimensional settings. In this course students will be guided through the essential ideas of multivariable calculus, including partial derivatives, multiple integrals and vector calculus, and their applications. These mathematical tools are used extensively in the physical sciences and engineering, and in other areas including economics and computer graphics. Learning objectives After the course, students are expected to: Be confident in handling functions of two or more variables and familiar with how they can be represented graphically Understand the key concepts of multivariable calculus, including partial derivatives, the gradient vector, multiple integrals, line and surface integrals, the divergence and curl of a vector function Know how such derivatives and integrals are calculated and some of their uses Be able to apply these ideas to real world problems Have improved analytic, computational and problem solving skills Homework Homework is optional. You can do it for your own good but are not required to turn them in. The reason I don’t collect homework anymore is because solutions are everywhere online (even ChatGPT can do them now) so checking your homework is no longer a good metric to know your learning effort. However, I will be available to answer your questions related to the homework. Assessment During the course, students are expected to compute their own percentage points based on the following scheme. The instructor is not responsible for providing the running percentage. Form of assessment Weight Weekly quizzes (Wednesday) 40% Midterm 30% Final 30% The following is the non-negotiable letter grade breakdown. It is based on common practice in the United States for standard courses such as Calculus. Letter Grade Percentage A [93,100] A- [90,93) B+ [87,90) B [83,87) B- [80, 83) C+ [77,80) C [73,77) C- [70,73) D+ [67,70) D [60, 66) F [0,60) Core content Chapters 12 - 16 of Stewart. Vectors and Geometry of Space Vector Functions Partial Derivatives Multiple Integrals Vector Calculus Time expectations Some materials require time to be accustomed to. Some students are quicker than others. However, on average, you should expect 10-15 hours per week (including class time) on the materials in order to know the subject relatively well. Collaboration &amp; Plagiarism Plagiarism is the act of submitting the intellectual property of another person as your own. It is one of the most serious of academic offenses. Acts of plagiarism include, but are not limited to: Copying, or allowing someone to copy, all or a part of another person’s work and presenting it as your own, or not giving proper credit. Purchasing a paper from someone (or a website) and presenting it as your own work. Re-submitting your work from another course to fulfill a requirement in another course. Further details can be found in the Code of Academic Integrity [link]. Learning Support In addition to your course instructors, there are other resources available to support your academic work at Fulbright, including one-on-one consultations with learning support staff, supplementary workshops, and both individual and group tutoring and mentoring in course content, language learning, and academic skills. If you would like to request learning support, please contact Fulbright Learning Support (https://learning-support.notion.site). Wellbeing Mental health and wellbeing are essential for the success of your academic journey. The Fulbright Wellness Center provides various services including counseling, safer community, and accessibility services. If you are experiencing undue personal or academic stress, are feeling unsafe, or would like to know more about issues related to wellbeing, please contact the Wellness Center via wellness@fulbright.edu.vn or visit the Wellness Center office on Level 5 of the Crescent campus. For more information, pleaes check https://onestop.fulbright.edu.vn/s/article/Health-and-Wellness-Introduction Tentative Course Schedule The following schedule will be updated as we go so that students will know what to watch/read before/after class. Week Topcs Read Homework 1 Vectors and Geometry Chapter 12 12.1: 11 - 37, 12.2: 1 - 28, 12.3: 1 - 24 2 Projection and Cross Product Chapter 12 12.3: 39 - 55, 12.4: 1 - 39 3 Equations of lines and planes Chapter 12 12.5: 6 - 31 Cylinders and Quadratic Surfaces Chapter 12 12.6: 1 - 38 4 Vector functions: limits, continuity, derivatives Chapter 13 13.1: 1 - 32 , 13.2: 2 - 40 5 13.3: 1 - 9, 13 - 29, 42 - 50, Good to know but not necessary: 59 - 63 6 Functions of several variables: limits, continuity Chapter 14 14.1: 1 - 52 7 Partial derivatives Chapter 14 14.3: 10 - 58, 14.4: 1 - 18, 25 - 34 8 Chain rule, directional derivative Chapter 14 14.5: 1 - 38, 14.6: 4 - 34 "],["vectors-matrices.html", "1 Vectors &amp; Matrices 1.1 Basics Rules to manipulate vectors Properties of vector operations 1.2 Products 1.3 Matrices", " 1 Vectors &amp; Matrices 1.1 Basics Reading: Stewart Chapter 12, Thomas Calculus Chapter 12, Active Calculus Chapter 9 You should be able to answer the following questions after reading this section: What is a vector? What does it mean for two vectors to be equal? How do we add two vectors together and multiply a vector by a scalar? How do we determine the magnitude of a vector? What is a unit vector How do we find a unit vector in the direction of a given vector? Typically, we talk about 3-dimensional vectors (as discussed in Stewart and Thomas). However, since talking about \\(n\\)-dimensional vectors doesn’t require much more effort, we will talk about \\(n\\)-dimensional vectors instead. Definition 1.1 An \\(n\\)-dimensional Euclidean space \\(\\mathbb{R}^n\\) is the Cartesian product of \\(n\\) Euclidean spaces \\(\\mathbb{R}\\). Definition 1.2 An \\(n\\)-dimensional vector \\(\\textbf{v}\\in \\mathbb{R}^n\\) is a tuple \\[\\begin{equation} \\textbf{v} = \\langle v_1,\\dots, v_n \\rangle \\,, \\end{equation}\\] where \\(v_i \\in \\mathbb{R}\\). In dimensions less than or equal to 3, we represent a vector geometrically by an arrow, whose length represents the magnitude. Remark. A point in \\(\\mathbb{R}^n\\) is also represented by an \\(n\\)-tuple but with round brackets. A vector connecting two points \\(A= (a_1, \\dots, a_n)\\) and \\(B=(b_1, \\dots, b_n)\\) can be constructed as \\[\\begin{equation*} \\textbf{x} = \\langle b_1-a_1, \\dots, b_n - a_n \\rangle \\,. \\end{equation*}\\] We denote the above vector as \\(\\vec{AB}\\) where \\(A\\) is the tail (initial point) and \\(B\\) is the tip/head (terminal point). We denote \\(\\textbf{0}\\) to be the zero vector, i.e., \\[\\begin{equation*} \\textbf{0} = \\langle 0, \\dots, 0 \\rangle \\,. \\end{equation*}\\] Definition 1.3 The length of a vector \\(\\textbf{v}\\) (denoted by \\(| \\textbf{v}|\\)) is defined to be \\[\\begin{equation} |\\textbf{v}| = \\sqrt{ v_1^2 + \\dots + v_n^2} \\,. \\end{equation}\\] Definition 1.4 A unit vector is a vector that has magnitude 1. Exercise 1.1 Turn a vector \\(\\textbf{v} \\in \\mathbb{R}^n\\) into a unit vector with the same direction. Rules to manipulate vectors Let \\(\\textbf{a}, \\textbf{b} \\in \\mathbb{R}^n\\) and \\(c,d \\in \\mathbb{R}\\). Then, \\[\\begin{equation*} c( \\textbf{a} + \\textbf{b}) = \\langle c a_1 + c b_1, \\dots, c a_n + c b_n \\rangle = c\\textbf{a} + c\\textbf{b} \\,, \\end{equation*}\\] and \\[\\begin{equation*} (c+d) \\textbf{a} = c\\mathbf{a} + d\\mathbf{a} \\,. \\end{equation*}\\] These formulas are deceptively simple. Make sure you understand all the implications. Because of this rule, sometimes it is good to write vectors in terms of elementary vectors: \\[\\begin{equation*} \\mathbf{u} = u_1 \\mathbf{e_1} + \\dots + u_n \\mathbf{e_n} \\,, \\end{equation*}\\] where \\(e_i = \\langle 0,\\dots, 1, \\dots, 0\\rangle\\) is the vector which has zero at all entries except that the \\(i^{th}\\) entry is 1. In 3D, \\[\\begin{equation*} \\mathbf{e_1} = \\mathbf{i} \\,, \\qquad \\mathbf{e_2} = \\mathbf{j} \\,, \\qquad \\mathbf{e_3} = \\mathbf{k} \\,. \\end{equation*}\\] Properties of vector operations Read the book (Make sure you understand the geometric intepretation) 1.2 Products 1.2.1 Dot product How is the dot product of two vectors defined and what geometric information does it tell us? How can we tell if two vectors in \\(\\mathbb{R}^n\\) are perpendicular? How do we find the projection of one vector onto another? Definition 1.5 The dot product of vectors \\(\\textbf{u} = \\langle u_1, \\dots, u_n \\rangle\\) and \\(\\textbf{v} = \\langle v_1, \\dots, v_n \\rangle\\) in \\(\\mathbb{R}^n\\) is the scalar \\[\\begin{equation*} \\textbf{u} \\cdot \\textbf{v} = u_1 v_1 +\\dots + u_n v_n \\,. \\end{equation*}\\] Properties of dot product Let \\(\\textbf{u}, \\textbf{v}, \\textbf{w} \\in \\mathbb{R}^n\\). Then, \\(\\textbf{u}\\cdot \\textbf{v} = \\textbf{v}\\cdot \\textbf{u}\\), \\((\\textbf{u} + \\textbf{v})\\cdot \\textbf{w} = (\\textbf{u}\\cdot \\textbf{w}) + (\\textbf{v}\\cdot \\textbf{w})\\), If \\(c\\) is a scalar, then \\((c \\textbf{u})\\cdot \\textbf{w} = c (\\textbf{u}\\cdot \\textbf{w})\\). Theorem 1.1 (Law of cosine) If \\(\\theta\\) is the angle between the vectors \\(\\textbf{u}\\) and \\(\\textbf{v}\\), then \\[\\begin{equation*} \\textbf{u}\\cdot \\textbf{v} = |\\textbf{u}|| \\textbf{v}| \\cos \\theta \\,. \\end{equation*}\\] Corollary 1.1 Two vectors \\(\\textbf{u}\\) and \\(\\textbf{v}\\) are orthogonal to each other if \\(\\textbf{u} \\cdot \\textbf{v} = 0\\). Projection Let \\(\\textbf{u}, \\textbf{v}\\in \\mathbb{R}^n\\). The component of \\(\\textbf{u}\\) in the direction of \\(\\textbf{v}\\) is the scalar \\[\\begin{equation*} \\mathrm{comp}_{\\mathbf{v}}\\mathbf{u} = \\frac{\\mathbf{u}\\cdot \\mathbf{v}}{|\\mathbf{v}|} \\,, \\end{equation*}\\] and the projection of \\(\\mathbf{u}\\) onto \\(\\mathbf{v}\\) is the vector \\[\\begin{equation*} \\mathrm{proj}_{\\mathbf{v}}\\mathbf{u} =\\left( \\mathbf{u}\\cdot \\frac{\\mathbf{v}}{|\\mathbf{v}|}\\right) \\frac{\\mathbf{v}}{|\\mathbf{v}|} = \\frac{\\mathbf{u}\\cdot \\mathbf{v}}{\\mathbf{v} \\cdot\\mathbf{v}} \\mathbf{v} \\,. \\end{equation*}\\] 1.2.2 3D special: Cross product This concept is very specific to \\(\\mathbb{R}^3\\). It will not make sense in other dimensions. Definition 1.6 Let \\(\\mathbf{a}, \\mathbf{b} \\in \\mathbb{R}^3\\). The cross product of \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\) is defined to be \\[\\begin{equation*} \\mathbf{a} \\times \\mathbf{b} = \\langle a_2 b_3 - a_3 b_2, a_3b_1 - a_1 b_3, a_1b_2 - a_2b_1 \\rangle \\,. \\end{equation*}\\] Theorem 1.2 Let \\(\\theta\\) be the angle between \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\). Then, \\[\\begin{equation*} | \\mathbf{a} \\times \\mathbf{b} | = |\\mathbf{a}||\\mathbf{b}| \\sin\\theta \\,. \\end{equation*}\\] Theorem 1.3 The vector \\(\\mathbf{a}\\times \\mathbf{b}\\) is orthogonal to both \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\). 1.2.3 Distance from a point We can use the cross and dot products to measure the distance of one point to either a plane or a line. Let \\(P \\in \\mathbb{R}^n\\) and \\(\\vec{r}(t) = R_0 + t \\vec{v}\\) be a line. Then the distance from \\(P\\) to \\(\\vec{r}(t)\\) is \\[ Dist = \\frac{| \\vec{R_0 P} \\times \\vec{v}|}{| \\vec{v} |}\\] 1.3 Matrices A matrix is an 2 dimensional array with rows and columns. \\[ A = \\begin{pmatrix} A_{11} &amp; \\dots &amp; A_{1n}\\\\ \\vdots &amp; &amp; \\vdots \\\\ A_{n1} &amp; \\dots &amp; A_{nn} \\end{pmatrix}\\] Another way to write out matrix \\(A\\) is \\[ A = (A_{ij})\\] where the first index \\(i\\) represents the row and the second index \\(j\\) represents the column. 1.3.1 Operations on matrices Addition: let \\(A\\) and \\(B\\) be two matrices with same dimension \\(m\\times n\\). Then \\(A + B\\) is an \\(m\\times n\\) matrix such that \\[[A + B]_{ij} = A_{ij} + B_{ij}.\\] Scalar multiplication: let \\(A\\) be a \\(m\\times n\\) matrix, \\(c\\) is a constant scalar. then \\(cA\\) is a \\(m\\times n\\) matrix such that \\[((cA)_{ij}) = (cA_{ij}).\\] Matrix multiplication: let \\(A\\) be \\(m\\times n\\) matrix and \\(B\\) be \\(n\\times l\\) matrix. Then the multiplication \\(AB\\) is a \\(m\\times l\\) matrix such that \\[ [AB]_{ij} = \\sum_{k} A_{ik} B_{kj} .\\] 1.3.2 Linear transformation A linear transformation is a function \\(f: \\mathbb{R}^n \\to \\mathbb{R}^m\\) such that \\[ f(a \\vec{u} + b \\vec{v} ) = a f(\\vec{u}) + b f(\\vec{v}) \\] for all \\(a,b \\in \\mathbb{R}\\) and \\(u,v \\in \\mathbb{R}^n\\). It turns out that every linear transformation \\(f: \\mathbb{R}^n \\to \\mathbb{R}^m\\) can be represented as a \\(m\\times n\\) matrix. "],["some-basic-equations-in-mathbbr3.html", "2 Some basic equations in \\(\\mathbb{R}^3\\) 2.1 Equations for lines 2.2 Equations for planes 2.3 Cylinders 2.4 Quadric surfaces", " 2 Some basic equations in \\(\\mathbb{R}^3\\) Just to build some toy examples for the future, we will play with some basic equations in three dimensions. 2.1 Equations for lines A line is a collection of points that is parallel to a vector and goes through a specific point. To capture this idea, we have the following representation for a line \\[\\begin{equation*} L = \\{\\mathbf{r}(t) \\,| \\mathbf{r}(t) = \\mathbf{r}_0 + t \\mathbf{v}, t\\in \\mathbb{R}\\} \\,, \\end{equation*}\\] where \\({r}_0\\) is the initial position and \\(\\mathbf{v}\\) is the direction. The equation for \\(\\mathbf{r}(t)\\) is called a vector equation for a line \\(L\\). Let \\(\\mathbf{v} = \\langle v_1, v_2, v_3 \\rangle\\) and \\(\\mathbf{r}_0 = ( x_0, y_0, z_0 )\\). The parametric equations of \\(L\\) is the following system of equations \\[\\begin{gather*} x = x_0 + v_1 t\\,, \\\\ y = y_0 + v_2 t\\,, \\\\ z = z_0 + v_3 t \\,. \\end{gather*}\\] This leads to the symmetric equations of \\(L\\) \\[\\begin{equation*} \\frac{x - x_0}{v_1} = \\frac{y - y_0}{v_2} = \\frac{z - z_0}{v_3} \\,. \\end{equation*}\\] Definition 2.1 Two lines are parallel if their directional vectors are parallel (scalar multiple of each other). Two lines that are not parallel and don’t intersect each other are said to be skew. 2.2 Equations for planes A plane is a collection of points that is perpendicular to one specific direction represented by a some vector called a normal vector. Note that due to scaling, there are more than one normal vector. To capture this idea, we have the following representation of a plane \\[\\begin{equation*} P = \\{ \\mathbf{r} \\, | \\, \\mathbf{n} \\cdot (\\mathbf{r}- \\mathbf{r}_0 ) = 0 \\} \\,. \\end{equation*}\\] This is called a vector equation for the plane \\(P\\). Multiplying things out, we have the scalar equation of the plane \\(P\\) with normal vector \\(\\mathbf{n} = \\langle n_1, n_2, n_3 \\rangle\\) through a point \\(P_0(x_0, y_0, z_0)\\) \\[\\begin{equation*} n_1(r_1- x_0) + n_2 (r_2 - y_0) + n_3(r_3 - z_0) = 0 \\,. \\end{equation*}\\] The equation of the form \\[\\begin{equation*} ax + by + cz + d = 0 \\end{equation*}\\] is called a linear equation. Definition 2.2 Two planes are said to be parallel if their normal vectors are parallel. If two planes are not parallel, they intersect in a straight line and the angle between the two planes is defined to be the angle between the two normal vectors. 2.3 Cylinders Definition 2.3 A cylinder is a surface that consists of all lines (called rulings) that are parallel to a given line. Example 2.1 \\(z = x^2\\) \\(x^2 + y^2 = 1\\) 2.4 Quadric surfaces Definition 2.4 A quadric surface is the graph of a second-degree equation in three variables \\(x,y\\) and \\(z\\). The equation that represents these surfaces is \\[Ax^2 + By^2 + Cz^2 + Dz = E\\,.\\] Example 2.2 Ellipsoid \\[\\frac{x^2}{a^2} + \\frac{y^2}{b^2} + \\frac{z^2}{c^2} = 1\\,. \\] Hyperbolic paraboloid \\[\\frac{y^2}{b^2} - \\frac{x^2}{a^2} = \\frac{z}{c} \\,.\\] Elliptical cone \\[\\frac{x^2}{a^2} + \\frac{y^2}{b^2} = \\frac{z^2}{c^2} \\,.\\] Read the books for more surfaces and pictures. "],["functions-in-higher-dimensions.html", "3 Functions in higher dimensions 3.1 Functions of several variables 3.2 Vector functions 3.3 Activity: on osculating circle and curvature", " 3 Functions in higher dimensions 3.1 Functions of several variables Definition 3.1 A function of several variables is a function \\(f: D \\to C\\) where \\(D \\subseteq \\mathbb{R}^m\\) and \\(C \\subseteq \\mathbb{R}^n\\), where \\(m\\geq 2\\) and \\(n\\geq 1\\). \\[f({x}) = ( f_1(x_1,\\dots, x_m),\\dots, f_n(x_1,\\dots, x_m) ) \\,.\\] \\(D\\) is called the domain of \\(f\\) and \\(C\\) is called the codomain of \\(f\\). The domain of \\(f\\) is where each of the component \\(f_i\\) of \\(f\\) is defined. Example 3.1 The following are some examples of multivariable functions \\(f(x,y) = x^2 - 2xy + y^2\\) \\(f(x,y,z) = \\frac{1}{1 - xy^2}\\) 3.2 Vector functions 3.2.1 Limit, continuity and differentiation The expression in the vector equation for a line is an example of a function that maps from \\(\\mathbb{R}\\) to \\(\\mathbb{R}^n\\). There’s no one who would stop us from considering more general kinds of function. Definition 3.2 A vector function (vector-valued function) is a function that has the codomain that belongs to \\(\\mathbb{R}^n\\) where \\(n\\geq 2\\). In other words, \\(f: D \\to \\mathbb{R}^n\\). Example 3.2 The following are some examples of vector functions. \\(\\mathbf{r}(t) = \\mathbf{r}_0 + t\\mathbf{v}\\) \\(\\mathbf{f}(t) = \\langle \\cos(t),\\sin(t), t \\rangle\\) Note that my definition is more general than that in the book. However, In this course, whenever we talk about vector valued function, we will only refer to that which has one dimensional domain (\\(D \\subseteq \\mathbb{R}\\)). By and large, there’s nothing different between a vector function and a one-variable scalar function. All the concepts such as limit, continuity and differentiability are applied to each coordinate the same way as in one dimensional case. Theorem 3.1 Let \\(\\mathbf{r}: \\mathbb{R}\\to \\mathbb{R}^n\\), given by \\(\\mathbf{r}(t) = \\langle r_1(t), \\dots , r_n(t) \\rangle\\). Then, \\(\\mathbf{r}\\) is said to be continuous at \\(t_0\\) if \\[\\begin{equation*} \\mathbf{r}(t_0) = \\lim_{t\\to t_0} \\mathbf{r}(t) \\,, \\end{equation*}\\] where \\[\\begin{equation*} \\lim_{t\\to t_0} \\mathbf{r}(t) = \\langle \\lim_{t\\to t_0}r_1(t) , \\dots , \\lim_{t\\to t_0} r_n(t) \\rangle \\,. \\end{equation*}\\] Furthermore, we can define the derivative of \\(\\mathbf{r}\\) \\[\\begin{equation*} \\frac{d}{dt} \\mathbf{r}(t) = \\mathbf{r}&#39;(t) = \\lim_{h\\to 0} \\frac{\\mathbf{r}(t+h) - \\mathbf{r}(t)}{h} \\end{equation*}\\] if this limit exists. When \\(\\mathbf{r}:I \\to \\mathbb{R}^n\\) (\\(I\\) is an interval in \\(\\mathbb{R}\\)) is continuous, we call it a space curve (to describe the intuitive picture of what a curve should look like in our mind). Geometrically, if \\(\\mathbf{r}&#39;(t)\\) exists and \\(\\mathbf{r}&#39;(t) \\not= \\mathbf{0}\\), it represents the tangent vector of the curve \\(\\mathbf{r}\\) at \\(t\\). Definition 3.3 A parametric equation for a curve is an equation of the form \\[ x=x(t)\\,, \\quad y = y(t)\\,, \\quad z = z(t) \\,. \\] Typical differentiation rules apply. Theorem 3.2 (Differentiation rules) \\((\\mathbf{u}(t) + \\mathbf{v}(t))&#39; = \\mathbf{u}&#39;(t) + \\mathbf{v}&#39;(t)\\) \\((c \\mathbf{u}(t))&#39; = c \\mathbf{u}&#39;(t)\\) \\((f(t) \\mathbf{u}(t))&#39; = f&#39;(t) \\mathbf{u}(t) + f(t) \\mathbf{u}&#39;(t)\\) \\((\\mathbf{u}(t) \\cdot \\mathbf{v}(t))&#39; = \\mathbf{u}&#39;(t)\\cdot \\mathbf{v}(t) + \\mathbf{u}(t)\\cdot \\mathbf{v}&#39;(t)\\) \\((\\mathbf{u}(t) \\times \\mathbf{v}(t))&#39; = \\mathbf{u}&#39;(t)\\times \\mathbf{v}(t) + \\mathbf{u}(t)\\times \\mathbf{v}&#39;(t)\\) \\((\\mathbf{u}(f(t)))&#39; = \\mathbf{u}&#39;(f(t)) f&#39;(t)\\) 3.2.2 Integrals There are different ways to play with integrals for vector functions, each has its own interpretation and physical applications. 3.2.2.1 Indefinite integral \\[\\begin{equation*} \\int_a^b \\mathbf{r}(t) \\, dt = \\left\\langle \\int_a^b r_1(t) \\, dt, \\int_a^b r_2(t) \\, dt, \\int_a^b r_3(t) \\, dt \\right\\rangle \\end{equation*}\\] 3.2.2.2 Arc Length and curvature Definition 3.4 The length the curve \\(\\mathbf{r}:[a,b] \\to \\mathbb{R}^n\\) is defined to be \\[\\begin{equation*} L = \\int_a^b \\left| \\mathbf{r}&#39;(t) \\right| \\, dt \\,. \\end{equation*}\\] If one wants to keep track the length of the curve \\(\\mathbf{r}:[a,b] \\to \\mathbb{R}^n\\) made by an airplane at any time \\(t\\), one uses the arc length function \\[\\begin{equation*} \\ell(t) = \\int_a^t \\left| \\mathbf{r}&#39;(u) \\right| \\, du \\,. \\end{equation*}\\] Re-parametrize with respect to arc length The nice thing about \\(\\ell(t)\\) is that it is a strictly increasing function with respect to \\(t\\), given that \\(\\mathbf{r}&#39;\\) is non-zero for all \\(t\\). Therefore, letting \\(s = \\ell(t)\\), we can talk about the inverse of \\(\\ell\\), \\(\\ell^{-1}:[0,L] \\to [a,b]\\) \\[\\begin{equation*} t = \\ell^{-1}(s) \\,. \\end{equation*}\\] Therefore, we can re-write \\[\\begin{equation*} \\mathbf{r}(t) = \\mathbf{r}(\\ell^{-1}(s)) \\,. \\end{equation*}\\] Theorem 3.3 \\[\\left| \\frac{d r(t)}{ds} \\right| = 1 \\,.\\] Thus, \\[l(s) = \\int_0^s \\left| \\frac{d}{ds} \\mathbf{r}(t) \\right| \\, dt = s \\,.\\] Because of the unchanging nature of the arc-length (with respect to the parametrization), it is used to define a geometric quantity of a space curve called curvature. Definition 3.5 (curvature) Let \\(\\mathbf{T}(t)\\) be the unit tangent vector of the curve \\(\\mathbf{r}:[a,b] \\to \\mathbb{R}^3\\). The curvature of \\(\\mathbf{r}(t(s))\\) is defined to be \\[\\begin{equation*} \\kappa(s) = \\left| \\frac{d \\mathbf{T}(t(s))}{ds}\\right| \\,. \\end{equation*}\\] To convert this into the parameter \\(t\\), we write \\(s= s(t)\\) and use chain rule to get. Theorem 3.4 We have that \\[\\begin{equation*} \\kappa(s(t)) = \\frac{|\\mathbf{T}&#39;(t)|}{|\\mathbf{r}&#39;(t)|} \\,. \\end{equation*}\\] 3.2.3 Space curve in \\(\\mathbb{R}^3\\) and motion in space Read the book. This part is not required but it is so beautiful, you may want to read it as an exercise at home (to test how much you understand what we’ve been discussing so far). 3.3 Activity: on osculating circle and curvature For those who are interested in the geometrical meaning of the curvature without having to accept from the book that the curvature is the inverse of the radius of the osculating circle, please take a look at https://github.com/sonv/MultiCalc/blob/main/Writing/latexbuild/osculating.pdf. "],["partial-derivatives.html", "4 Partial derivatives 4.1 Limits and continuity 4.2 Partial derivatives 4.3 Differentiability 4.4 Chain rule 4.5 Directional derivative 4.6 Tangent planes", " 4 Partial derivatives 4.1 Limits and continuity The following definition is from Stewart. Definition 4.1 Let \\(f: \\mathbb{R}^n \\to \\mathbb{R}^m\\) be a function. Then we say that the limit of \\(f(x)\\) as \\(x\\) approaches \\(a\\) is \\(L\\) and we write \\[\\lim_{x \\to a} f(x) = L\\] if for every number \\(\\epsilon &gt; 0\\) there is a corresponding number \\(\\delta &gt; 0\\) such that \\(|f(x,y) - L| &lt; \\epsilon\\) if \\(| x - a| &lt; \\delta\\). Finding if a function has limit as a point in higher dimension is not as simple as the case for 1 dimension. Determining whether a multivariable function has a limit sometimes is an art and it requires a lot of experiences and practice. However, there are certain rules that could help us. Theorem 4.1 Let \\(L,M\\) and \\(k\\) be real numbers and that \\[\\begin{equation*} \\lim_{x \\to a} f(x,y) = L \\,, \\qquad \\lim_{x \\to a} g(x,y) = M \\,. \\end{equation*}\\] We then have \\(\\displaystyle \\lim_{x \\to a} (f(x) + g(x)) = L + M\\), \\(\\displaystyle \\lim_{x \\to a} (k f(x)) = kL\\), \\(\\displaystyle \\lim_{x \\to a} (f(x) g(x)) = LM\\), \\(\\displaystyle \\lim_{x \\to a} \\frac{f(x)}{g(x)} = \\frac{L}{M}\\) if \\(M \\not= 0\\), \\(\\displaystyle \\lim_{x \\to a} {f(x)^p} = L^p\\) for \\(p&gt;0\\), Strategy to find out that a two-variable function does NOT have a limit. If \\(\\lim_{(x,y) \\to (a,b)} f(x,y) = L_1\\) as \\((x,y) \\to (a,b)\\) along a path \\(C_1\\), and \\(\\lim_{(x,y) \\to (a,b)} f(x,y) = L_2\\) as \\((x,y) \\to (a,b)\\) along a path \\(C_2\\), where \\(L_1 \\neq L_2\\), then \\(\\lim_{(x,y) \\to (a,b)} f(x,y)\\) does not exist. Example 4.1 \\(\\lim_{(x,y)\\to (0,0)} \\frac{x^2 - y^2}{x^2 + y^2}\\) does not exist. \\(\\lim_{(x,y)\\to (0,0)} \\frac{xy}{x^2 + y^2}\\) does not exist. \\(\\lim_{(x,y)\\to (0,0)} \\frac{xy^2}{x^4 + y^4}\\) does not exist. \\(\\lim_{(x,y)\\to (0,0)} \\frac{3x^2y}{x^2 + y^2} = 0\\). 4.2 Partial derivatives given a function \\(f:\\mathbb{R}^n \\to \\mathbb{R}^m\\), the partial derivative with respect to the \\(j\\)th variable \\(x_j\\) of the \\(i\\)th output at \\(a \\in \\mathbb{R}^n\\) is \\[\\begin{equation*} \\frac{ \\partial }{\\partial x_j} f_{i}(a) = \\lim_{h\\to 0} \\frac{ f(a_1, \\dots, a_{i-1}, a_i + h , a_{i+1}, \\dots, a_n) - f(a_1, \\dots, a_{i-1}, a_i , a_{i+1}, \\dots, a_n)}{h} \\,. \\end{equation*}\\] Notations. The partial derivatives sometimes have different notations: \\[\\begin{equation*} \\partial_j f_i (a) = \\partial_{x_j} f_i (a) = \\frac{ \\partial }{\\partial x_j} f_{i}(a) . \\end{equation*}\\] From here, one can define higher partial derivatives such as the following \\[\\begin{equation*} \\partial^3_{1 2 3} f_i (a) = \\frac{\\partial}{\\partial x_1} \\frac{\\partial}{\\partial x_2} \\frac{\\partial}{\\partial x_3} f_i (a)\\,. \\end{equation*}\\] Note that the power over the symbol \\(\\partial\\) represents the order of derivatives. Some important notations Let \\(f:D \\to \\mathbb{R}\\) be a function. We write the following, if exist, \\[\\begin{equation*} \\nabla f = \\begin{bmatrix} \\partial_{x_1} f\\\\ \\vdots \\\\ \\partial_{x_n} f\\\\ \\end{bmatrix} \\end{equation*}\\] \\[\\begin{equation*} \\Delta f = \\partial_{x_1}^2 f + \\dots \\partial_{x_n}^2 f \\,. \\end{equation*}\\] 4.3 Differentiability Definition 4.2 (Differentiability) Let \\(f:\\mathbb{R}^n \\to \\mathbb{R}^m\\). \\(f\\) is said to be differentiable at \\(a \\in \\mathbb{R}^n\\) if there exists a linear transformation \\([Df]_a\\) such that for every vector \\(\\mathbf{h} \\in \\mathbb{R}^n\\) \\[\\lim_{|\\mathbf{h}| \\to 0} \\frac{ f(a + \\mathbf{h}) - f(a) - [Df]_a \\mathbf{h}}{| \\mathbf{h} |} = 0 . \\] For \\(f:\\mathbb{R}^n \\to \\mathbb{R}^m\\), \\([Df]_a\\) is a \\(m\\times n\\) matrix given by \\[[Df]_a = \\left[ \\frac{\\partial }{\\partial x_j} f_i (a)\\right].\\] This is called the Jacobian matrix of \\(f\\) at \\(a\\). For some good intuition, please go to https://mathinsight.org/differentiability_multivariable_definition. Theorem 4.2 Let \\(f:\\mathbb{R}^n \\to \\mathbb{R}^m\\). If the partial derivatives \\(\\partial_j f_i\\) exist near \\(a\\in \\mathbb{R}^n\\) and are continuous at \\(a\\), then \\(f\\) is differentiable at \\(a\\). Theorem 4.3 Let \\(f:\\mathbb{R}^n \\to \\mathbb{R}^m\\). If \\(f\\) is differentiable at \\(a\\) then \\(f\\) is continuous at \\(a\\). 4.4 Chain rule Theorem 4.4 Let \\(f: \\mathbb{R}^n \\to \\mathbb{R}^l, g: \\mathbb{R}^m \\to \\mathbb{R}^n\\) be differentiable functions. Then, \\[ [D (f\\circ g)]_a = [Df]_{g(a)} [Dg]_a. \\] Here’s a special case Theorem 4.5 Let \\(f: \\mathbb{R}^n \\to \\mathbb{R}, g: \\mathbb{R}^m \\to \\mathbb{R}^n\\) be differentiable functions. Then, \\[z(y_1, \\dots, y_m) = (f\\circ g)(y_1, \\dots, y_m)\\] is differentiable and \\[\\begin{equation*} \\frac{\\partial z}{\\partial y_i} = \\sum_{j=1}^n \\frac{\\partial f}{\\partial x_j} \\frac{\\partial g_j}{\\partial y_i} \\,. \\end{equation*}\\] 4.5 Directional derivative Definition 4.3 Let \\(\\mathbf{u} \\in \\mathbb{R}^n\\). The directional derivative of \\(f:\\mathbb{R}^n \\to \\mathbb{R}\\) at \\(a\\in \\mathbb{R}^n\\) in the direction of \\(\\mathbf{u}\\) is the following limit (if exists) \\[\\begin{equation*} D_{\\mathbf{u}} f(a) = \\lim_{h \\to 0} \\frac{ f( a + h \\mathbf{u}) - f(a)}{h}\\,. \\end{equation*}\\] How can one compute directional derivative? Theorem 4.6 If \\(f:\\mathbb{R}^n \\to \\mathbb{R}\\) is differentiable then \\[\\begin{equation*} D_{\\mathbf{u}} f(a) = \\nabla f(a) \\cdot \\mathbf{u} \\,. \\end{equation*}\\] 4.6 Tangent planes Let’s think about tangent planes in a more systematic way, based on the definition of a plane learned in the first chapter. Recall the \\(c\\)-level surface of a function \\(f(x,y,z)\\) is the collection \\[\\begin{equation*} \\{ (x,y,z) | f(x,y,z) = c \\} \\,. \\end{equation*}\\] Definition 4.4 The tangent plane at the point \\(P(x_0, y_0, z_0)\\) on the \\(c\\)-level surface of a differentiable \\(f\\) is the plane through \\(P_0\\), normal to \\(\\nabla f (x_0, y_0, z_0)\\). "],["optimization.html", "5 Optimization 5.1 First and second derivative tests 5.2 Constrained optimization", " 5 Optimization 5.1 First and second derivative tests Read Stewart Chapter 14, Thomas Chapter 14, We will study multivariable scalar functions \\[ f: D \\to \\mathbb{R}\\,,\\] where \\(D\\subseteq \\mathbb{R}^n\\), \\(n\\geq 2\\). Definition 5.1 A function \\(f:D \\to \\mathbb{R}\\) has a local maximum at \\(\\mathbf{x_0}\\) if \\(f(\\mathbf{x_0}) \\geq f(\\mathbf{x})\\) for \\(\\mathbf{x} \\in B_\\delta(\\mathbf{x_0})\\) for small enough \\(\\delta\\). \\(f\\) has a global maximum at \\(\\mathbf{x_0}\\) if \\(f(\\mathbf{x_0}) \\geq f(\\mathbf{x})\\) for \\(\\mathbf{x} \\in D\\). \\(f\\) has a local (global) minimum at \\(\\mathbf{x_0}\\) if \\(-f\\) has a local (global) maximum at \\(\\mathbf{x_0}\\) Theorem 5.1 (First derivative test) Let \\(f:D \\to \\mathbb{R}\\) be a function. If \\(\\mathbf{x_0}\\) is a local minimum and \\(f\\) has partial derivatives at \\(\\mathbf{x_0}\\). Then \\[\\begin{equation*} \\partial_{x_i} f(\\mathbf{x}_0) = 0 \\,. \\end{equation*}\\] The converse is not true, as having \\(\\nabla f(\\mathbf{x}_0) = \\mathbf{0}\\) does not mean that \\(f\\) has a local minimum at \\(\\mathbf{x}_0\\). Exercise 5.1 Think of a function that the converse to the above theorem is not true. This leads to the following notion. Definition 5.2 \\(\\mathbf{x}_0\\) is said to be a critical point of \\(f:D\\to \\mathbb{R}\\) if \\[\\begin{equation*} \\nabla f(\\mathbf{x}_0) = 0 \\end{equation*}\\] or one of the partial derivatives \\(\\partial_{x_i} f(\\mathbf{x}_0)\\) fails to exist. Please pay attention about the “fail to exist” condition. Theorem 5.2 (Second derivative test for functions of 2 variables) Suppose the second partial derivatives of \\(f\\) are continuous near \\((a,b)\\) and suppose that \\((a,b)\\) is a critical point of \\(f\\). Let \\[\\begin{equation*} D = f_{xx}(a,b) f_{yy}(a,b) - f_{xy}(a,b)^2\\,. \\end{equation*}\\] If \\(D&gt;0\\) and \\(f_{xx}(a,b) &gt;0\\), then \\(f(a,b)\\) is a local minimum. If \\(D&gt;0\\) and \\(f_{xx}(a,b) &lt;0\\), then \\(f(a,b)\\) is a local maximum. If \\(D&lt;0\\), then \\(f(a,b)\\) is neither a local maximum nor local minimum. If \\(D=0\\), then we cannot conclude. Theorem 5.3 (Extreme value theorem) If \\(f\\) is continuous on a closed and bounded set \\(D\\). Then, \\(f\\) attains an absolute minimum and an absolute maximum in \\(D\\). 5.1.1 Algorithm to find absolute maxima and minima on closed bounded regions Find the values of \\(f\\) at the critical points of \\(f\\) in \\(D\\). Find the extreme values of \\(f\\) on the boundary of \\(D\\). The largest of the values from steps 1 and 2 is the absolute maximum value; the smallest of these values is the absolute minimum value. 5.2 Constrained optimization Constrained optimization takes various forms, depending on the assumptions. We will deal with the most straight forward form. The problem we will study is the following: Maximize/minimize a function \\(f:D\\to \\mathbb{R}\\), subject to a constraint (side condition) of the form \\(g(\\mathbf{x}) = k\\), for some constant \\(k\\in \\mathbb{R}\\). Theorem 5.4 (Method of Lagrange Multiplier) Suppose the maximum/minimum values of \\(f\\) exist and \\(\\nabla g(\\mathbf{x}) \\not=0\\) where \\(g(\\mathbf{x}) = k\\). To find the maximum and minimum values of \\(f\\) subject to constraint \\(g(\\mathbf{x}) = k\\), we do the following: Find all values of \\(\\mathbf{x}\\) and \\(\\lambda \\in \\mathbb{R}\\) such that \\[\\begin{equation*} \\nabla f(\\mathbf{x}) =\\lambda \\nabla g(\\mathbf{x})\\,, \\end{equation*}\\] and \\[\\begin{equation*} g(\\mathbf{x}) = k \\,. \\end{equation*}\\] Evaluate \\(f\\) at all the points \\(\\mathbf{x}\\) that result from step 1. The largest of these values is the maximum of \\(f\\); the smallest is the minimum value of \\(f\\). "],["multiple-integrals.html", "6 Multiple integrals 6.1 Basic definition 6.2 Iterated integrals 6.3 Change of coordinates", " 6 Multiple integrals Read Stewart Chapter 15 and Thomas Chapter 15 Notations: Rectangle \\(R= [a_1,b_1]\\times \\dots \\times [a_n, b_n] \\subseteq \\mathbb{R}^n\\). 6.1 Basic definition Definition 6.1 Let \\(f\\) be a function on a rectangle \\(R\\). An n-fold Riemann sum for \\(f\\) over \\(R\\) is a sum of the following form \\[\\begin{equation*} \\sum_{i_1=1}^{m_1}\\dots \\sum_{i_n=1}^{m_n} f(\\xi_{i_1\\dots i_n}) \\Delta A \\,, \\end{equation*}\\] where \\(\\Delta A = \\Delta x_1\\times\\dots \\times \\Delta x_n\\), \\(\\Delta x_i = (b_i-a_i)/m_i\\), \\(\\xi_{i_1\\dots i_n}\\in R_{i_1\\dots i_n}\\), \\(R_{i_1\\dots i_n}= \\prod [a_i + (i_1-1)\\Delta x, a_i+ i_1\\Delta x_i]\\). Definition 6.2 The double integral of \\(f\\) over a rectangle \\(R \\subseteq \\mathbb{R}^2\\) is \\[\\begin{equation*} \\iint_{R} f(x,y) \\, dA = \\lim_{m,n\\to \\infty} \\sum_{i=1}^m \\sum_{j=1}^n f(\\xi_{ij}) \\Delta A \\end{equation*}\\] if the limit exists. The triple integral of \\(f\\) over a rectangle \\(R \\subseteq \\mathbb{R}^3\\) is \\[\\begin{equation*} \\iiint_{R} f(x,y) \\, dA = \\lim_{m,n,l\\to \\infty} \\sum_{i=1}^m \\sum_{j=1}^n \\sum_{k=1}^l f(\\xi_{ijk}) \\Delta A \\end{equation*}\\] if the limit exists. 6.1.1 Some properties of integrals Let \\(U, V\\) be disjoint domains, then \\[\\begin{equation*} \\iint_{U \\cup V} f \\, dA = \\iint_U f \\, dA + \\iint_V f\\, dA \\,. \\end{equation*}\\] \\[\\begin{equation*} \\iint_U (f + g) \\, dA = \\iint_U f \\, dA + \\iint_V f \\, dA \\,. \\end{equation*}\\] 6.2 Iterated integrals Suppose that \\(f\\) is integrable on \\(R= [a,b]\\times [c,d]\\). An iterated integral of \\(f\\) is defined as \\[\\begin{equation*} \\int_a^b A(x) \\, dx \\,, \\end{equation*}\\] where \\[\\begin{equation*} A(x) = \\int_c^d f(x,y) \\, dy \\,. \\end{equation*}\\] Typically, we write the above as \\[\\begin{equation*} \\int_a^b \\int_c^d f(x,y) \\, dy dx \\,. \\end{equation*}\\] This means that we integrate in \\(y\\) before in \\(x\\)– always integrate the inner part first. Similarly, we can define an iterated integral in a different order \\[\\begin{equation*} \\int_c^d \\int_a^b f(x,y) \\, dx dy \\,. \\end{equation*}\\] The biggest question: Is it true that \\[\\begin{equation*} \\int_a^b \\int_c^d f(x,y) \\, dy dx = \\int_c^d \\int_a^b f(x,y) \\, dx dy \\,? \\end{equation*}\\] Theorem 6.1 (Special case of Fubini) If \\(f\\) is continuous on the rectangle \\(R\\), then \\[\\begin{equation*} \\iint_R f(x,y) \\, dA = \\int_a^b \\int_c^d f(x,y) \\, dy dx = \\int_c^d \\int_a^b f(x,y) \\, dx dy \\,. \\end{equation*}\\] Example 6.1 Let \\[\\begin{equation*} f(x,y) = \\frac{x^2 - y^2}{(x^2 + y^2)^2} \\,. \\end{equation*}\\] \\[\\begin{equation*} \\int_0^1\\int_0^1 f(x,y) \\,dy dx = \\frac{\\pi}{4} = - \\int_0^1\\int_0^1 f(x,y) \\, dx dy \\,. \\end{equation*}\\] Everything we discuss here is true for three-variable functions. 6.3 Change of coordinates A coordinate transformation is a function \\(\\varphi\\), which is bijective and differentiable for which \\(D\\varphi\\) is invertible at all points in the domain. Here, \\[\\begin{equation*} D\\varphi = \\begin{pmatrix} \\partial_1 \\varphi_1 &amp; \\partial_2 \\varphi_1 \\\\ \\partial_1 \\varphi_2 &amp; \\partial_2 \\varphi_2 \\end{pmatrix} \\,. \\end{equation*}\\] We will need to re-call the notion of invertible matrix here. For an \\(n\\times n\\) matrix \\(A\\), it is invertible iff \\(\\det A \\not= 0\\),. Theorem 6.2 Let \\(f\\) be a function of \\((x,y)\\) defined on the domain \\(D\\). Let \\[\\begin{equation*} \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\varphi(u,v) \\end{equation*}\\] for some coordinate change function \\(\\varphi: D \\to S\\). If \\(f\\) is continuous and \\(\\varphi\\) is differentiable, then \\[\\begin{equation*} \\int_S f \\, dA = \\int_D f\\circ \\varphi |\\det D \\varphi| \\, dA \\end{equation*}\\] 6.3.1 Applications of change of coordinates 6.3.1.1 Polar coordinate In \\(\\mathbb{R}^2\\), when the region of integration is a section of a disk centered at \\(0\\). Let \\[\\begin{equation*} \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\varphi(r,\\theta) = \\begin{pmatrix} r\\cos\\theta \\\\ r\\sin\\theta \\end{pmatrix} \\,, \\end{equation*}\\] where \\(a \\leq r \\leq b\\) and \\(\\alpha \\leq \\theta \\leq \\beta\\). 6.3.1.2 Cylindrical coordinate In \\(\\mathbb{R}^3\\), when the region of integration is part of a cylinder. Let \\[\\begin{equation*} \\begin{pmatrix} x \\\\ y \\\\z \\end{pmatrix} = \\varphi(r,\\phi,\\theta) = \\begin{pmatrix} r\\cos\\theta\\\\ r\\sin\\theta\\\\ z \\end{pmatrix} \\,, \\end{equation*}\\] where \\(a \\leq r \\leq b\\), \\(\\alpha \\leq \\theta \\leq \\beta\\). 6.3.1.3 Spherical coordinate In \\(\\mathbb{R}^3\\), when the region of integration is a section of a ball centered at \\(0\\). Let \\[\\begin{equation*} \\begin{pmatrix} x \\\\ y \\\\z \\end{pmatrix} = \\varphi(\\rho,\\phi,\\theta) = \\begin{pmatrix} \\rho\\sin\\phi\\cos\\theta\\\\ \\rho\\sin\\phi\\sin\\theta\\\\ \\rho \\cos\\phi \\end{pmatrix} \\,, \\end{equation*}\\] where \\(a \\leq \\rho \\leq b\\), \\(\\alpha \\leq \\theta \\leq \\beta\\), and \\(c \\leq \\phi \\leq d\\). "],["vector-calculus.html", "7 Vector Calculus 7.1 Vector fields 7.2 Line integrals 7.3 Green’s Theorem 7.4 Curl and Divergence 7.5 Surface integrals 7.6 Stokes’ and Divergence Theorem", " 7 Vector Calculus Read Chapter 16 in Stewart. 7.1 Vector fields Definition 7.1 Let \\(D\\) be a domain on \\(\\mathbb{R}^n\\). A vector field on \\(\\mathbb{R}^n\\) is a function \\(\\mathbf{F}: D \\to \\mathbb{R}^n\\) that assign each point \\(\\mathbf{x}\\in D\\) to a vector \\(\\mathbf{F}(\\mathbf{x}) \\in \\mathbb{R}^n\\). In \\(\\mathbb{R}^2\\), one typically write the vector fields in terms of component functions \\(P, Q\\) \\[\\mathbf{F}(x,y) = P(x,y) \\mathbf{i} + Q(x,y) \\mathbf{j}\\,.\\] In \\(\\mathbb{R}^3\\), one typically write the vector fields in terms of component functions \\(P, Q, R\\) \\[\\mathbf{F}(x,y,z) = P(x,y) \\mathbf{i} + Q(x,y) \\mathbf{j} + R(x,y,z) \\mathbf{k}\\,.\\] Example 7.1 Newton’s Law of Gravitation \\[\\begin{equation*} \\mathbf{F}(\\mathbf{x}) = - \\frac{m M G}{| \\mathbf{x}|^3 } \\mathbf{x} \\,, \\end{equation*}\\] where \\(\\mathbf{x}\\) is the position in \\(\\mathbb{R}^3\\). Example 7.2 Coulomb’s Law for the electric force exerted by an electric charge \\(Q\\) at the origin on another charge \\(q\\) at a point \\(\\mathbf{x}\\in \\mathbb{R}^3\\). \\[\\begin{equation*} \\mathbf{F}(\\mathbf{x}) = \\frac{ \\epsilon q Q}{|\\mathbf{x}|^3} \\mathbf{x} \\,. \\end{equation*}\\] 7.2 Line integrals Let’s focus on \\(\\mathbb{R}^2\\). We now perform a Riemann-sum-like action. Definition 7.2 Let \\(C\\) be a curve. The line integral of \\(f\\) along \\(C\\) is defined as \\[\\begin{equation*} \\int_C f(x,y) \\, ds = \\lim_{n\\to \\infty} \\sum_{i=1}^n f(x_i^*, y_i^*) \\Delta s_i \\,, \\end{equation*}\\] where \\(\\Delta s_i\\) is the length of a subarc of \\(C\\). Proposition 7.1 Suppose \\(C\\) is smooth and is parametrized by \\(\\mathbf{r}(t), a\\leq t \\leq b\\). Then \\[\\begin{equation*} \\int_C f(x,y) \\, ds = \\int_a^b f(\\mathbf{r}(t)) |\\mathbf{r}&#39;(t)| \\, dt \\,. \\end{equation*}\\] Note: when integrating with respect to arc length like this, reverse the direction of traversing the curve \\(C\\) will NOT result in a change of sign of the final solution. \\[\\begin{equation*} \\int_{-C} f(x,y) \\, ds = \\int_C f(x,y) \\, ds \\,. \\end{equation*}\\] Now we define line integrals of vector fields. Definition 7.3 Let \\(\\mathbf{F}\\) be a continuous vector field defined on a curve \\(C\\). Then the line integral of \\(\\mathbf{F}\\) along \\(C\\) is defined as \\[\\begin{equation*} \\int_C \\mathbf{F} \\cdot d \\mathbf{r} = \\int_C \\mathbf{F}\\cdot \\mathbf{T} \\, ds \\,, \\end{equation*}\\] where \\(\\mathbf{T}\\) is the unit tangent vector. Proposition 7.2 Suppose \\(C\\) is smooth and parametrized by \\(\\mathbf{r}(t), a \\leq t \\leq b\\). Then \\[\\begin{equation*} \\int_C \\mathbf{F} \\cdot d \\mathbf{r} = \\int_a^b \\mathbf{F}(\\mathbf{r}(t)) \\cdot \\mathbf{r}&#39;(t) \\, dt \\end{equation*}\\] We also use the following notations \\[\\begin{align*} \\int_C f(x,y) dx := \\int_a^b f(x(t), y(t) ) \\, x&#39;(t) \\, dt \\,, \\\\ \\int_C f(x,y) dy := \\int_a^b f(x(t), y(t) ) \\, y&#39;(t) \\, dt \\,, \\\\ \\end{align*}\\] We can abbreviate the above by \\[\\begin{equation*} \\int_C P(x,y) dx + \\int_C Q(x,y) dy = \\int_C P(x,y) \\, dx + Q(x,y) \\, dy \\,. \\end{equation*}\\] So, \\[\\begin{equation*} \\int_C \\mathbf{F} \\cdot d \\mathbf{r} = \\int_C P \\, dx + Q \\, dy \\,. \\end{equation*}\\] Note: as oppose to integrating the arc length, reversing the order of the above integrals will change the sign of the integral. This is because the arc length is always positive, while \\(\\Delta x\\) and \\(\\Delta y\\) could be either positive or negative. \\[\\begin{equation*} \\int_{-C} P(x,y) \\, dx + Q(x,y) \\, dy = -\\int_C P(x,y) \\, dx + Q(x,y) \\, dy \\,. \\end{equation*}\\] Theorem 7.1 (Fundamental Theorem for line integrals) Let \\(C\\) be a smooth curve given by the parametrization \\(\\mathbf{r}(t)\\), \\(a \\leq t \\leq b\\). Let \\(f\\) be a differentiable function of two or three variables whose gradient vector \\(\\nabla f\\) is continuous on \\(C\\). Then, \\[\\begin{equation*} \\int_C \\nabla f \\cdot d\\mathbf{r} = f(\\mathbf{r}(b)) - f(\\mathbf{r}(a)) \\,. \\end{equation*}\\] Definition 7.4 A closed curve is a curve that starts and ends at the same point. A simple closed curve is a closed curve that never crosses itself. Sometimes, if \\(C\\) is a closed curve, we signify it by the following notation \\[\\begin{equation*} \\oint_C \\nabla f \\cdot d\\mathbf{r} \\,. \\end{equation*}\\] Corollary 7.1 If \\(C\\) is a closed curve and \\(f:\\mathbb{R}^n \\to \\mathbb{R}\\) is a smooth function, then \\[\\begin{equation*} \\oint_C \\nabla f \\cdot d\\mathbf{r} = 0 \\,. \\end{equation*}\\] Definition 7.5 A vector field \\(\\mathbf{F}\\) is called a conservative vector field if it is the gradient of some scalar function, that is there exists a function \\(f\\) such that \\[\\begin{equation*} \\nabla f = \\mathbf{F} \\,. \\end{equation*}\\] Therefore, if \\(\\mathbf{F}\\) is a conservative vector field, then \\[\\begin{equation*} \\oint_C \\mathbf{F} \\cdot d\\mathbf{r} = 0 \\,. \\end{equation*}\\] 7.2.1 Independence of path Suppose \\(C_1\\) and \\(C_2\\) are two piecewise smooth curves that have the same initial point \\(A\\) and end point \\(B\\). Then, \\[\\begin{equation*} \\int_{C_1} \\mathbf{F}\\cdot d\\mathbf{r} = \\int_{C_2} \\mathbf{F} \\cdot d\\mathbf{r} \\end{equation*}\\] whenever \\(\\mathbf{F}\\) is conservative (Why?). The question is when is the converse true? The following example is an example when the converse is not always true. Example 7.3 Evaluate \\[\\begin{equation*} \\int_{C_i} x^2 \\, dy \\,, \\qquad i = 1,2 \\end{equation*}\\] where \\(C_1\\) is the line segments from \\((-1,-1) \\to (-1,1) \\to (1,1)\\) and \\(C_2\\) is the line segments from \\((-1,-1) \\to (1,-1) \\to (1,1)\\). To further the discussion, we need a few definitions. Definition 7.6 Let \\(\\mathbf{F}\\) be a continuous vector field with domain \\(D\\), we say that the line integral \\[\\begin{equation*} \\int_C \\mathbf{F} \\cdot d\\mathbf{r} \\end{equation*}\\] is independent of path if \\[\\begin{equation*} \\int_{C_1} \\mathbf{F}\\cdot d\\mathbf{r} = \\int_{C_2} \\mathbf{F} \\cdot d\\mathbf{r} \\end{equation*}\\] for all paths that have the same starting and ending points. Theorem 7.2 \\(\\int_C \\mathbf{F}\\cdot d\\mathbf{r}\\) is independent of path in \\(D\\) if and only if \\(\\oint_\\Gamma \\mathbf{F} \\cdot d\\mathbf{r} = 0\\) for every closed path \\(\\Gamma\\) in \\(D\\). Definition 7.7 A domain \\(D\\) is said to be open if around each point, we can draw an open ball around it. A domain \\(D\\) is said to be connected if for any two points, there is a path that connect them together. A domain \\(D\\) is said to be simply connected if is connected and there’s no hole in it. Theorem 7.3 Suppose \\(\\mathbf{F}\\) is a vector field that is continuous on an open connected region \\(D\\). If \\(\\int_C \\mathbf{F} \\cdot d \\mathbf{r}\\) is independent of path in \\(D\\), then \\(\\mathbf{F}\\) is a conservative vector field on \\(D\\). Proof. todo The above theorem gives a way to determine if a vector field is conservative or not, from the point of view of path independence. However, it is often difficult to check the path independence property as one has to integrate over ALL possible curves, and there are a lot of them… Another way is to take inspiration from Clairaut’s theorem. The question is to determine whether \\(\\mathbf{F}\\) is conservative, given the mixed partial derivatives of \\(P\\) and \\(Q\\) are the same, i.e., \\[\\begin{equation*} \\frac{\\partial P}{\\partial y} = \\frac{\\partial Q}{\\partial x}\\,. \\end{equation*}\\] (Compare this with Clairaut’s) Theorem 7.4 Let \\(\\mathbf{F} = P\\mathbf{i} + Q\\mathbf{j}\\) be a vector field on an open simply connected region \\(D\\). Suppose that \\(P\\) and \\(Q\\) have continuous first-order partial derivatives and \\[\\begin{equation*} \\frac{\\partial P}{\\partial y} = \\frac{\\partial Q}{\\partial x} \\end{equation*}\\] through out \\(D\\). Then \\(\\mathbf{F}\\) is conservative. Remark. The connectedness of \\(D\\) is crucial (why?). 7.3 Green’s Theorem Theorem 7.5 (Green's Theorem) Let \\(D\\) be an open bounded simply connected domain in \\(\\mathbb{R}^2\\), \\(\\Gamma\\) be the boundary of \\(D\\), and \\(\\mathbf{F} = P\\mathbf{i} + Q \\mathbf{j}\\) be a vector field. If \\(P\\) and \\(Q\\) have continuous partial derivatives on an open region that contains \\(D\\), then \\[\\begin{equation*} \\int_\\Gamma \\mathbf{F} \\cdot d \\ell = \\iint_D \\left( \\frac{\\partial Q}{\\partial x} - \\frac{\\partial P}{\\partial y} \\right) \\, dA \\,. \\end{equation*}\\] 7.4 Curl and Divergence Definition 7.8 Let \\(\\mathbf{F}\\) be a vector field in \\(\\mathbb{R}^3\\). If all partial derivatives of \\(P,Q,R\\) exist, then we define \\[\\begin{equation*} \\mathrm{curl}\\,\\mathbf{F} = \\left( \\frac{\\partial R}{\\partial y} - \\frac{\\partial Q}{\\partial z} \\right) \\mathbf{i} + \\left( \\frac{\\partial P}{\\partial z} - \\frac{\\partial R}{\\partial x} \\right) \\mathbf{j} + \\left( \\frac{\\partial Q}{\\partial x} - \\frac{\\partial P}{\\partial y} \\right) \\mathbf{k} \\,. \\end{equation*}\\] A different notation for \\(\\mathrm{curl} \\, \\mathbf{F}\\) is \\[\\begin{equation*} \\nabla \\times \\mathbf{F} \\,. \\end{equation*}\\] Theorem 7.6 If \\(f\\) is a function of 3 variables that has continuous second partial derivatives, then \\[\\begin{equation*} \\nabla \\times ( \\nabla f) = 0 \\,. \\end{equation*}\\] Theorem 7.7 Suppose \\(\\mathbf{F}\\) is a vector field on and simply connected domain \\(D\\) so that \\(P,Q,R\\) all have continuous partial derivatives. \\(F\\) is a conservative vector field if and only if \\(\\nabla \\times \\mathbf{F} = 0\\). Definition 7.9 Let \\(\\mathbf{F}\\) be a vector field in \\(\\mathbb{R}^3\\). If all partial derivatives of \\(P,Q,R\\) exist, then we define \\[\\begin{equation*} \\mathrm{div}\\,\\mathbf{F} = \\frac{\\partial P}{\\partial x} + \\frac{\\partial Q}{\\partial y} + \\frac{\\partial R}{\\partial z} \\,. \\end{equation*}\\] A different notation for \\(\\mathrm{div} \\, \\mathbf{F}\\) is \\[\\begin{equation*} \\nabla \\cdot \\mathbf{F} \\,. \\end{equation*}\\] Theorem 7.8 Suppose \\(\\mathbf{F}\\) is a vector field on a domain \\(D\\) and \\(P,Q,R\\) have continuous second-order partial derivatives. Then, \\[\\begin{equation*} \\nabla \\cdot (\\nabla \\times \\mathbf{F}) = 0 \\,. \\end{equation*}\\] 7.5 Surface integrals 7.5.1 Parametric surfaces Similar to the way we parametrize a curve by a one-variable vector function \\(\\mathbf{r}(t)\\), we can parametrize a surface by a two-variable vector function \\(\\mathbf{r}(u,v)\\). We will only deal with surfaces in \\(\\mathbb{R}^3\\) in this section. So, the parametrization of a surface \\(S\\) should be \\[\\begin{equation*} \\mathbf{r}: D\\subseteq \\mathbb{R}^2 \\to \\mathbb{R}^3 \\,. \\end{equation*}\\] We often write \\[\\begin{equation*} \\mathbf{r}(u,v) = x(u,v) \\mathbf{i} + y(u,v) \\mathbf{j} + z(u,v) \\mathbf{k} \\,. \\end{equation*}\\] From this parametrization, we get to talk about the tangent plane of \\(S\\) at the point \\(\\mathbf{r}(u,v)\\), which is the plane that contains two tangent vectors \\[\\begin{equation*} \\mathbf{r}_u (u,v) = \\frac{\\partial x}{\\partial u} \\mathbf{i} + \\frac{\\partial y}{\\partial u} \\mathbf{j} + \\frac{\\partial z}{\\partial u} \\mathbf{k} \\,, \\end{equation*}\\] and \\[\\begin{equation*} \\mathbf{r}_v (u,v) = \\frac{\\partial x}{\\partial v} \\mathbf{i} + \\frac{\\partial y}{\\partial v} \\mathbf{j} + \\frac{\\partial z}{\\partial v} \\mathbf{k} \\,. \\end{equation*}\\] 7.5.2 Surface integral Definition 7.10 Let \\(S\\) be a surface with parametrization. The surface integral of \\(f\\) over the surface \\(S\\) is \\[\\begin{equation*} \\iint_S f(x,y,z) \\, dS = \\lim_{m,n\\to \\infty} \\sum_{i=1}^m \\sum_{j=1}^n f(P_{ij}^*) \\Delta S_{ij} \\,. \\end{equation*}\\] Similarly to the line integral, one can show that \\[\\begin{equation*} \\iint_S f(x,y,z) \\, dS = \\iint_D f(\\mathbf{r}(u,v)) | \\mathbf{r_u}\\times \\mathbf{r_v} | \\, dA \\,. \\end{equation*}\\] 7.5.3 Orientation of the surface Given a surface \\(S\\), we define the orientation of it as following If \\(S\\) has a boundary, then the positive orientation of the surface is that when one walks along the boundary of the surface with the head points in that direction, the surface is on the left. If \\(S\\) does not have a boundary, then the positive orientation is the direction of the outward normal vector. 7.5.4 Surface integral of vector fields Definition 7.11 If \\(\\mathbf{F}\\) is a continuous vector field on an oriented surface \\(S\\) (parametrized by \\(\\mathbf{r}(u,v)\\)) with unit normal vector \\(\\mathbf{n}\\), then the surface integral of \\(\\mathbf{F}\\) over \\(S\\) is \\[\\begin{equation*} \\iint_S \\mathbf{F}\\cdot \\, d\\mathbf{S} = \\iint_S \\mathbf{F}\\cdot \\mathbf{n} \\, dS = \\iint_S \\mathbf{F}\\cdot (\\mathbf{r}_u\\times \\mathbf{r}_v) \\, dA \\,. \\end{equation*}\\] The integral is called the flux of \\(\\mathbf{F}\\) across \\(S\\). 7.6 Stokes’ and Divergence Theorem Theorem 7.9 (Stokes' Theorem) Let \\(S\\) be an oriented smooth surface that is bounded by a simple closed smooth boundary curve \\(\\partial S\\) with positive orientation. Let \\(\\mathbf{F}\\) be a vector field whose components have continuous partial derivatives on an open region in \\(\\mathbb{R}^3\\) that contains \\(S\\). Then \\[\\begin{equation*} \\int_{\\partial S} \\mathbf{F} \\cdot \\, d\\mathbf{r} = \\iint_S \\nabla \\times \\mathbf{F} \\cdot d\\mathbf{S} \\,. \\end{equation*}\\] The boundary of an area is a curve. Similarly, the boundary of a solid is a surface. Theorem 7.10 (Divergence Theorem) Let \\(E\\) be a simple solid region and let surface \\(\\partial E\\) be the boundary of \\(E\\), given with positive (outward) orientation. Let \\(\\mathbf{F}\\) be a vector field whose components have continuous partial derivatives. Then, \\[\\begin{equation*} \\iint_{\\partial E} \\mathbf{F} \\cdot d\\mathbf{S} = \\iiint_E \\mathrm{div} \\mathbf{F} \\, dV \\,. \\end{equation*}\\] "]]
